\documentclass{article}

\usepackage{arxiv}

\usepackage{fontspec}
\setmainfont{Linux Libertine O}
\usepackage{bm}
\usepackage{polyglossia}
\setdefaultlanguage{english}
\setotherlanguage{russian}

\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}

\usepackage[numbers]{natbib}
\usepackage{amsthm}
\usepackage{doi}
\usepackage{xcolor}

\usepackage{todonotes}
\newcommand{\todoask}[1]{\todo[color=blue!40]{\textbf{Ask:} #1}}
\newcommand{\todocheck}[1]{\todo[color=green!40]{\textbf{Check:} #1}}
\newcommand{\todoread}[1]{\todo[color=orange!40]{\textbf{Read:} #1}}
\newcommand{\todocomment}[1]{\todo[color=purple!40]{\textbf{Comment:} #1}}


\title{ Robust Detection of AI-Generated Images}

\author{%
    Kilinkarov Georgii \\
    Chair of Data Analysis\\
    Moscow Institute of Physics and Technology\\
    Moscow, Russia \\
    \texttt{kilinkarov.gv@phystech.edu} \\
    \And
    Daniil Dorin  \\
    Affiliation \\
    Address \\
    \texttt{email} \\
    \AND
    Andrey Grabovoy \\
    Affiliation \\
    Address \\
    \texttt{email}
}
\date{}

\hypersetup{
    pdftitle={Comparative Analysis of Data-Driven Approaches for Hydrological Forecasting},
    pdfsubject={cs.LG},
    pdfauthor={Eldar Khuzin, Novikov Ivan, Abramov Dmitrii},
    pdfkeywords={Flood discharge, Rainfall-runoff modeling, More}
}

\begin{document}
\maketitle

\section{Аннотация}
В связи с улучшением качества машиносгенерированных изображений становится очень сложно отличать реальное изображение от сгенерированных.  Существующие на данный момент решения имеют низкую обощающую способность. В этой статье рассматриваются разные модели, в том числе несвязанные с нейронными сетями. Также используется вся существующая информацию и модели, для подбора наилучшего решения. Дополнительно строится модель, которая сначала проверяет метод генерации, потом уже использует конкретную модель для этого метода генерации. Помимо этого, используются методы графических редакторов, на основе искуственного интеллекта.


\keywords{Машинносгенерированные изображения}

\section{Введение}
\label{sec:introduction}

В современном мире в связи с развитием генераторов изображений человеческому глазу стало уже слишком сложно отличать настоящие изображение и машиносгенерированное. Ещё сложнее человеку отличить реальное изображение от реального, но с использованием графического редактора.\cite{OnlineDetection} В связи с доступностью этих сервисов стали очень распространены разные виды мошенничества, использующие машиногенерацию. Таким образом задача детекции машинносгенерированных изображений стала очень важна.


На данный момент не существует общего подхода к решению этой задачи, устойчивого относильно появления новых моделей. Например, появление диффузионных моделей генерации изображений свело сущесвтующие на тот момент методы к точности около 60 процентов\cite{GenImage}. Таким образом, существующие на данный момент методы имеют низкую обощающую способность. Актуальные научные статьи на эту тему можно поделить на три типа: построение устойчивой модели с помощью добавления новых типов генерации в фазу обучения\cite{AivsAi, OnlineDetection}, решение задачи с помощью методов, не использующих AI (с помощью классических методов и рассмотрения спектра света)\cite{ZeroShot}, создание новых более мощных датасетов для данный задачи\cite{GenImage, CIFAKE}.


AI-модели обучается на всё более новых и новых датасетах, включая в себя новые способы генерации, создаются способы онлайн-обучения \cite{OnlineDetection}, что улучшает постепенно качество, но концептуально не отличается от предыдущих методов и не обеспечивает устойчивость в случае, если появится более иновационный метод генерации. До появления диффузионных моделей высокое качество показывал метод, рассматривающий спектр по Фурье \cite{ZeroShot}. Но на диффузионных моделях не показывает уже высокого качества.

Таким образом, в этой статье проводится попытка объеденить существующие методы и найти новый способ детекции машиносгенерированных изображений. Новизна заключается в объединении методов и построении модели, предполагающей сначала тип генерации, а потом проверяющей на генерацию сгенерировано ли изображение уже непосредственно с предположением определенного типа генерации.

Преимущество этого подхода заключается в подборе оптимальной модели для конкретного класса генирации, проблема заключается в высокой цене ошибки: если произойдет ошибка в предсказании класса генерации, то будет использоваться заведомо плохо подходящая модель.


\section{Постановка задачи}
\label{sec:problem_statement}
Задана выборка $$\mathfrak{D} = \{\bm{x_i}, y_i \},\ i= 1, ..., N,$$ где $\bm{x_i} \in \mathbb{N}_0^{H \times W \times C}$~--- изображение размера $H \times W \times C$, $y_i \in \{ 0, 1\}.$ \\

Необходимо построить отображение $\bm{F}: \mathbb{N}_0^{H \times W \times C} \rightarrow \{ 0, 1 \}.$

Для нахождения оптимального отображения \( \bm{F}^* \) в классе моделей \( \mathcal{F} \) используется Binary Cross-Entropy Loss (BCE):
\[
	\bm{F}^* = \arg\min_{\bm{F}^* \in \mathcal{F}} \operatorname{BCE}(F).
\]

\section{Теория}
\label{sec:theory}
Отображение $\bm{F}: \mathbb{N}_0^{H \times W \times C} \rightarrow \{ 0, 1 \}.$ представляет из себя композицию двух отображений: $\bm{F} = \bm{f} \circ \bm{g}$, где:
\begin{center}
    $\bm{f}: \mathbb{N}_0^{H \times W \times C} \rightarrow \mathbb{R}^{d}$ ~--- векторизация изображения
\end{center}
\begin{center}
    $\bm{g}: \mathbb{R}^{d} \rightarrow \{ 0, 1 \}$ ~--- классификатор
\end{center}
В статье для обучения $\bm{F}$ обучается только голова классифкатора $\bm{g}$, а $\bm{f}$ фиксировано и не обучается. Для векторизатора $\bm{f}$ рассматривается Clip от OpenAI. \\

Clip - модель на основе траснформера, представляющая из себя серию из 5 ResNets и 3 Vision Transformers. На выходе получаем размер 512. Эта модель является одним из state-of-art классификаторов, для многих задач достаточно сделать голову классификатора и получится высокая точность для классификатора.

\section{Вычислительный эксперимент}
Целью вычислительного эксперемента является проверка качества двухступенчатой классификации. \\

В работе рассматривается датасет данных Artifact \cite{artifact}, для вычислительного эксперемента взято 13200 изображений. Датасет включается в себя реальные изображения и 25 методов генерации изображений, включая 13 GANs, 7 диффузионных, и 5 других методов генерации. Изображения по классам берутся так, чтобы их количество было одинаково для всех классов, кроме real(их очень много) и ddpm(их очень мало). Количество данных для классов на тестовой выборке можно посмотреть в таблице.

В качестве основной модели будет использоваться Clip от OpenAI \ref{sec:theory}.
Выборка была поделена на обучающую и тестовую в соотношении 70 на 30. \\

В работе рассматривается несколько разных моделей для сравнения и на основе этих эксперементов выбирается лучшая. За базовую модель была взята модель с Clip бинарным классификаором. Вторая модель к Clip добавляет два линейных слоя с функцией активацией Relu Один линейный слой с выходом 26(именно столько классов изображений существует в датасете). Третья модель является многоклассовым классификатором, но Test Accuracy считается для возможности сравнения как для бинарной модели. \\

Для оценки качества модели используются следующие оценочные метрики: Accuracy, Recall, Precision, ROC-AUC, PR-curve. Эти метрики помогают в проверке качества моделей и сравнения моделей между собой. Для многоклассовой классификацией также рассматривается confusion matrix для понимаю природы ошибок и слабых мест модели. Модели сравниваются по всем выше перечисленным метрикам, а также по графику обучения, включающие в себя 3 графика: график Loss от номера эпохи, Train, Test Accuracy от номера эпохи и время, затраченное на backward и forward от номера эпохи.\\

Обучение происходит с помощью оптимизатора Adam, с критерием CrossEntropy и 20 эпохами. 

\section{Результаты}

Ниже представлена таблица для базовой модели для разнообразных метрик и разных классов. Для конкретного класса проведен фильтр на то, является ли реальная метка таковой, поэтому precision = 1, a recall и accuracy одинаковы. \\
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{base_model_acc.png}
    \caption{Результаты базовой модели для разных классов}
    \label{fig:example}
\end{figure}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{base_Roc_Pr.png}
    \caption{Roc-Auc и PR-curve для базовой модели}
    \label{fig:example}
\end{figure}

Также было проведено сравнение первых двух моделей. Сравниваем по 3 графикам: график Loss от номера эпохи, график Accuracy от номера эпохи и время на проходы от номера эпохи. \\

Cравним модели и обнаружим, что многоклассовая получилась совсем неудачной, когда как увеличение слоев подняла качество без потери времени. \\





\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{train_curve.png}
    \caption{Сравнение первых двух моделей}
    \label{fig:example}
\end{figure}


\bibliographystyle{unsrtnat}
\bibliography{references}
\end{document}
